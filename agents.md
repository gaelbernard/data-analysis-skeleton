# Agent Instructions

You are assisting with a data analysis project that follows a structured pipeline. Read this document carefully before doing any work.

## Pipeline Overview

The project is organized into 5 stages. Data flows forward only — never skip a stage or create backward dependencies.

```
0_plan  →  1_data  →  2_db  →  3_analyses  →  4_output
```

| Stage | Reads from | Produces | Format |
|-------|-----------|----------|--------|
| `0_plan/` | (nothing) | plan.md, decisions.md | Markdown |
| `1_data/` | External sources | Raw data files + sources.yaml | CSV, JSON, XLSX, etc. |
| `2_db/` | `1_data/*` | `project.duckdb` + `schema.md` | DuckDB + Markdown |
| `3_analyses/` | `2_db/project.duckdb` | `results.json` + optional figures per subfolder | JSON + PDF/PNG |
| `4_output/` | `3_analyses/*/results.json` | Report, slides | Quarto → PDF |

## General Rules

- **Language**: Python. Use Pandas unless instructed otherwise.
- **Coding style**: Write concise, flat scripts. No `if __name__ == "__main__"`. Minimize functions — use them only when they genuinely reduce repetition. Top-level procedural code is preferred.
- **API keys**: Never hardcode API keys. Use a `.env` file with `python-dotenv`. See `.env.example` for the template.
- **Dependencies**: All Python dependencies go in `requirements.txt` at the root.
- **Skeleton improvements**: When you modify a generic file that could benefit future projects (agents.md, Makefile, helpers.py, templates, READMEs), prefix the commit message with `[skeleton]`. Example: `git commit -m "[skeleton] improve JSON schema documentation"`.

---

## Stage 0: Plan (`0_plan/`)

**Goal**: Define the project before writing any code.

Before starting, help the user clarify:
1. **Objective**: What question are we answering? Who is the audience?
2. **Input data**: What data do we need? Where does it come from?
3. **Transformations**: What cleaning, normalization, or enrichment is needed?
4. **Analyses**: What queries/calculations will answer the question?
5. **Output format**: Report? Slides? Dashboard? What structure?

Record the plan in `0_plan/plan.md`. Record key decisions (and their rationale) in `0_plan/decisions.md` throughout the project.

**When to update the plan**: If the analysis reveals that the original plan doesn't work (wrong data, unexpected results), update `plan.md` and log the decision in `decisions.md`.

---

## Stage 1: Data Collection (`1_data/`)

**Goal**: Gather all raw data needed for the project.

Rules:
- Every data file must be documented in `sources.yaml` with: filename, origin, URL (if applicable), date accessed, description, and format.
- Raw data is committed to git (unless too large — in that case, document how to obtain it and add a download script in `1_data/`).
- Never modify raw data files after collection. All transformations happen in `2_db/`.
- If data comes from an API or database, write a collection script in `1_data/` and document it in `sources.yaml`.

---

## Stage 2: Database (`2_db/`)

**Goal**: Transform raw data into a clean, queryable DuckDB database.

Rules:
- The output is always a single file: `project.duckdb`.
- The build script is `build_db.py`. It reads from `1_data/`, applies all transformations, and writes the DuckDB.
- Transformations include: importing raw files, cleaning text, normalizing values, computing derived columns (embeddings, categories, etc.), creating lookup tables.
- After building, auto-generate `schema.md` documenting all tables, columns, and types.
- The DuckDB is not committed to git (it's in `.gitignore`). It is rebuilt with `make db` or `python 2_db/build_db.py`.

**Important**: `schema.md` is the contract between `2_db/` and `3_analyses/`. Always keep it up to date. When the LLM writes SQL queries in `3_analyses/`, it should reference `schema.md` to know the exact table and column names.

---

## Stage 3: Analyses (`3_analyses/`)

**Goal**: Answer analytical questions by querying the DuckDB and producing structured JSON outputs.

### Structure

Each analysis lives in its own subfolder:

```
3_analyses/
  value_frequency/
    run.py              # Script: queries DB, writes results.json + optional figures
    results.json        # Output: structured JSON (see schema below)
    figures/            # Optional: figures generated by run.py
      bar_chart.pdf
  schein_levels/
    run.py
    results.json
  ...
```

### The JSON Contract

Every `results.json` must follow this schema:

```json
{
  "query": "SELECT ... FROM ...",
  "n_results": 38,
  "results": [
    {"col1": "value1", "col2": 123},
    {"col1": "value2", "col2": 456}
  ],
  "description": "Short sentence: what this analysis does",
  "interpretation": "Short sentence: what the results mean",
  "figures": [
    {
      "file": "figures/bar_chart.pdf",
      "caption": "What this figure shows"
    }
  ]
}
```

Fields:
- `query`: The exact SQL query used. Must be valid against the current `schema.md`.
- `n_results`: Number of rows in `results`.
- `results`: Array of objects — the raw query output in JSON format.
- `description`: One sentence explaining what we tried to do (in English).
- `interpretation`: One sentence interpreting the results (in English). Can be left empty initially and filled after reviewing.
- `figures`: Array of figure references (empty `[]` if no figures). Each entry has `file` (relative path) and `caption`.

### Rules for Analysis Scripts (`run.py`)

- Always connect to the DuckDB with `read_only=True`: `con = duckdb.connect("../../2_db/project.duckdb", read_only=True)`
- The script should be runnable from its own subfolder: `cd 3_analyses/my_analysis && python run.py`
- Output `results.json` in the same subfolder.
- If the DB schema changes, the query may break or return different results. In that case, update the query and re-run the script.
- Keep scripts concise and flat. No `if __name__ == "__main__"`.

### Rules for Figures

- Figures go in a `figures/` subfolder within the analysis folder.
- A figure must use the same data as the JSON results (or a subset). Never fetch additional data for a figure that isn't in the JSON.
- Every figure must be referenced in the `figures` array of `results.json`.
- Prefer PDF for vector graphics, PNG for raster.

### When to Create a New Analysis vs. Update an Existing One

- **New subfolder**: when answering a new question.
- **Update existing**: when refining the same question (adding a filter, changing a grouping).
- **Never delete**: if an analysis is superseded, rename the folder with a `_deprecated_` prefix.

---

## Stage 4: Output (`4_output/`)

**Goal**: Produce the final deliverable (report, slides, etc.) using Quarto.

### The Golden Rule

**Never write a number directly in a Quarto document.** Every number, count, percentage, or statistic must be loaded from a `results.json` in `3_analyses/`. If the data you need doesn't exist as a JSON, go back to `3_analyses/` and create a new analysis first.

### Loading Data

Use `helpers.py` to load analysis data in Quarto Python chunks:

```python
from helpers import load_analysis, load_figure

data = load_analysis("value_frequency")
# data["results"] → list of dicts
# data["n_results"] → int
# data["interpretation"] → string

fig_path = load_figure("value_frequency", "bar_chart.pdf")
```

### Figures in Reports

Figures are generated in `3_analyses/` (not in `4_output/`). The report references them by path using `load_figure()`. This ensures figures and data stay in sync.

### Templates

- `templates/report/` — LaTeX preamble, title page, styles for reports.
- `templates/slides/` — Beamer theme files for slides.

Customize these per project. When you create a reusable template improvement, commit with `[skeleton]` prefix.

### Rendering

```bash
cd 4_output && quarto render report.qmd
cd 4_output && quarto render slides.qmd
```

Or use `make report` / `make slides` from the project root.

---

## Orchestration (Makefile)

The `Makefile` at the root provides shortcuts:

```bash
make db          # Rebuild DuckDB from 1_data/
make analyses    # Run all run.py scripts in 3_analyses/
make report      # Render report with Quarto
make slides      # Render slides with Quarto
make all         # Run the full pipeline: db → analyses → report
```

---

## Troubleshooting Checklist

If something breaks, check in this order:

1. **Report shows wrong numbers?** → Re-run the analysis (`make analyses`), then re-render (`make report`).
2. **Analysis query fails?** → Check `2_db/schema.md` — did the DB schema change? Update the query in `run.py`.
3. **DB build fails?** → Check that raw data in `1_data/` hasn't changed format. Update `build_db.py`.
4. **Missing data for the report?** → Create a new analysis subfolder in `3_analyses/`. Never hardcode.
5. **API key error?** → Check `.env` file exists and has the right keys. See `.env.example`.
